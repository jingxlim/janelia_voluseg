########################
# timeouts and buffers
########################
# voluseg defined
spark.network.timeout=3600s
spark.storage.blockManagerSlaveTimeoutMs=3600s
spark.executor.heartbeatInterval=360s
# additional config from: https://wiki.int.janelia.org/wiki/display/ScientificComputing/Spark+on+LSF
spark.rpc.askTimeout=300s
spark.storage.blockManagerHeartBeatMs=30000
spark.rpc.retry.wait=30s
spark.kryoserializer.buffer.max=1024m
spark.core.connection.ack.wait.timeout=600s

############################
# memory and core settings
############################
spark.driver.maxResultSize=0
spark.python.worker.memory=3g
spark.driver.memory=120g
spark.executor.memory=480g
spark.executor.cores=30
spark.rpc.message.maxSize=10000

##legacy memory and core settings for full Broadwell with 6 executors. Uncomment to use these options.
# spark.driver.maxResultSize=0
# spark.python.worker.memory=3g  # this parameter is strongly advised. As it does not run under the executor jvm \,
#                                 pyspark will not respect the executor memory limits and will in fact compete with it.
# spark.driver.memory=140g       # make sure this parameter does not exceed your slot request \
#                                 for your driver and also leaves space for garbage collection.
# spark.executor.memory=50g      # this is for the jvm that is running each executor. \
#                                 Make sure it does not exceed your slot request when \
#                                 multiplied times the number of executors per worker, and leaves room for garbage collection.
# spark.executor.cores=5         # Number of cores per executor. The number of executors \
#                                 per worker will be determined by (worker slots requested)/(spark.executor.cores).
