########################
# timeouts and buffers
########################
# voluseg defined
spark.network.timeout=3600s
spark.storage.blockManagerSlaveTimeoutMs=3600s
spark.executor.heartbeatInterval=360s
# additional config from: https://wiki.int.janelia.org/wiki/display/ScientificComputing/Spark+on+LSF
spark.rpc.askTimeout=300s
spark.storage.blockManagerHeartBeatMs=30000
spark.rpc.retry.wait=30s
spark.kryoserializer.buffer.max=1024m
spark.core.connection.ack.wait.timeout=600s

############################
# memory and core settings
############################
spark.driver.maxResultSize=0
spark.python.worker.memory=3g
spark.rpc.message.maxSize=2046

## might be a good idea for exector.memory+driver.memory not to exceed total memory
## total should be less than the amount available
## ws1: 1006 GB  spark.driver.memory=120g spark.executor.memory=850g
## ws3: 1007 GB
# spark.driver.memory=120g
# spark.executor.memory=850g

## assume 10 tasks/core
## ws1: 96 cores: 960
## ws3: 256 cores: 2560
# spark.default.parallelism=960

## Following article: https://aws.amazon.com/blogs/big-data/best-practices-for-successfully-managing-memory-for-apache-spark-applications-on-amazon-emr/
spark.dynamicAllocation.enabled=false
spark.executor.cores=5
spark.executor.memory=45g
spark.driver.memory=120g
spark.driver.cores=5
spark.executor.instances=16
spark.default.parallelism=1280
